{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Food Deserts in Davidson County"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import math\n",
    "from sklearn.metrics.pairwise import haversine_distances # measure distance between lat, lng coordinates\n",
    "import ast # used for converting strings to underlying datatypes\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as BS\n",
    "from shapely.ops import unary_union # used for merging shape objects\n",
    "import folium\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**These are the criteria we will use for defining a food desert:**\n",
    "1. Poverty level in a census tract is >= 20% (low income)\n",
    "2. At least 33% of the census tract is >1 mile from a fresh food source in urban areas or >10 miles for rural areas (low access)\n",
    "\n",
    "**For the analysis we will need:**\n",
    "- The census tracts in Davidson County\n",
    "- Poverty levels for each census tract\n",
    "- Location of grocery stores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in census tracts in Davidson County"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned from the TN census tracts found here: https://www2.census.gov/geo/tiger/GENZ2018/shp/\n",
    "davidson_tracts = gpd.read_file('data/davidson_tracts.geojson')\n",
    "davidson_tracts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "davidson_tracts.boundary.plot(figsize = (20, 20));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the outline of Davidson county as well and set the Coordinate Reference System to match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "davidson_county = gpd.read_file('data/Davidson County Border (GIS).geojson')\n",
    "davidson_county.crs = \"EPSG:4326\"\n",
    "davidson_county.boundary.plot(figsize = (20, 20));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we have the census tract boundaries, we can look at poverty rates across them. For that we will import poverty count data from the census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned from data found here: https://censusreporter.org/data/table/?table=B17001&geo_ids=14000US47037016000,05000US47037,04000US47,01000US,140|05000US47037&primary_geo_id=14000US47037016000\n",
    "poverty_rates_davidson_tract = pd.read_csv('data/davidson_poverty_cleaned.csv', index_col = 0)\n",
    "poverty_rates_davidson_tract.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the columns we can see that the data show the `Total` population for a tract, as well as the number above and below the poverty line in the past 12 months, both over all and broken down by sex and age range. We only need the total numbers, so to simplify we can remove the other columns. While we're at it we can drop the first 3 aggregation rows. Then we can use the number below the poverty line and the total population to determine the percent below the poverty level for each tract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poverty_rates_davidson_tract = poverty_rates_davidson_tract.drop(columns = [c for c in poverty_rates_davidson_tract.columns if c not in ['geoid', 'name', 'Total:', 'Income in the past 12 months below poverty level:']])\n",
    "poverty_rates_davidson_tract = poverty_rates_davidson_tract.drop([0, 1, 2])\n",
    "\n",
    "poverty_rates_davidson_tract['pct_below_poverty_level'] = poverty_rates_davidson_tract['Income in the past 12 months below poverty level:']/poverty_rates_davidson_tract['Total:']\n",
    "poverty_rates_davidson_tract.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we have the poverty rates for each tract, we can determine the ones that are >20%. Since we will combine these data with additional geographic data, it would be best to first combine it with the census tract boundaries we already have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poverty_rates_davidson_tract['NAME'] = poverty_rates_davidson_tract['name'].str.split(' ').str[2].str[:-1]\n",
    "poverty_rates_davidson_tract.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "davidson_tracts = davidson_tracts.merge(poverty_rates_davidson_tract[['NAME', 'pct_below_poverty_level']],\n",
    "                                        how = 'left',\n",
    "                                        on = 'NAME')\n",
    "\n",
    "# fill missing values with median for ease\n",
    "davidson_tracts['pct_below_poverty_level'] = davidson_tracts['pct_below_poverty_level'].fillna(np.median(davidson_tracts['pct_below_poverty_level']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are interested in if a tract is above 20% poverty, we can add a new column that indicates if a tract is above or below 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "davidson_tracts['above_20_pct'] = (davidson_tracts['pct_below_poverty_level'] > 0.2).astype(int)\n",
    "davidson_tracts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Now we have gotten to a good point where we can address the first part of our criteria for where food deserts could occur: **Which census tracts have >20% poverty?**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(15, 15))\n",
    "ax = davidson_tracts.plot(ax=ax, column = 'above_20_pct', cmap='Set1', edgecolor = 'blue', alpha = 0.5)\n",
    "ax = davidson_county.boundary.plot(ax=ax, color='blue');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tracts in **gray** are above 20% poverty, while the ones in **red** are below 20% poverty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we know which tracts have above 20% poverty, we can find stores that sell fresh produce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding all the grocery stores that can be accessed by Davidson County residents is a little tough. There are a few curated lists but they are behind a paywall and may be out of date. For this analysis we'll walk through an example of how the Google Maps API can be used to get Supermarkets and other stores.\n",
    "\n",
    "Google Maps has many API endpoints, the one we'll use is the `nearbysearch` endpoint. For that we'll need to supply a **coordinate point**, a **radius**, and the **type** of store(s) to search for. The API does have limits so to make sure we are getting all the data we're expecting, we have to break the search down into smaller pieces. \n",
    "\n",
    "One important thing to consider is where to search for grocery stores. In general this seems obvious, but we should also consider the (literal) edge cases. For residents living at the edges of Davidson County, a grocery store could be within a mile _outside_ of the county limits. Additionally, the definition of a food desert is different for urban vs. rural areas. Urban areas look for grocery stores within _1_ mile, while rural areas look for grocery stores within _10_ miles. So some additional steps we need to take are:  \n",
    "1. Determine which census tracts are considered urban vs. rural\n",
    "2. If there are rural tracts, expand the search area to 10 miles around Davidson County\n",
    "3. Divide the search area into smaller parts to ensure we capture all the stores\n",
    "\n",
    "Determining \"rural\" census tracts is difficult, since urban areas are determined by population level, and census tracts are drawn to have approximately equal population levels. Luckily, Davidson County has outlined the **Nashville Urban Services District**, so let's start by comparing the urban area with the census tracts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "davidson_service_districts = gpd.read_file('data/Service Districts (GIS).geojson')\n",
    "davidson_service_districts.crs = \"EPSG:4326\"\n",
    "davidson_service_districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(15, 15))\n",
    "ax = davidson_tracts.plot(ax=ax, column = 'above_20_pct', cmap='Set1', edgecolor = 'blue', alpha = 0.5)\n",
    "ax = davidson_county.boundary.plot(ax=ax, color='blue')\n",
    "ax = davidson_service_districts[davidson_service_districts['name']=='Urban Services District'].plot(ax=ax, alpha = 0.4, edgecolor = 'black', linewidth = 3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The urban area roughly overlaps with census tracts but not fully. For this analysis let's say if at least 50% of the tract is in the urban area, then it is an urban tract.\n",
    "\n",
    "Determining how much of a shape overlaps with another is actually relatively straightforward. We can first subtract the urban area from a given tract, which will leave us with the tract area _outside_ of the urban area. Then we can divide that value by the total area of the tract. That will give us the proportion of the tract that is **rural**. We will use the `.area` attribute to work with numeric values. Once we have the ratio, we can determine `True` or `False`, is the ratio greater than 0.5. If it is, then the tract is **rural**\n",
    "\n",
    "One good approach to determine if each tract is urban or rural is the `.apply()` method. This method will take a function, and _apply_ it to each row. There is no pre-built function to check if a tract is urban or rural so let's make our own!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_urban_tract(row):\n",
    "    return int(((row['geometry'] - urban_service_area).area/row['geometry'].area) > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urban_service_area = davidson_service_districts.loc[0, 'geometry']\n",
    "\n",
    "davidson_tracts['is_rural'] = davidson_tracts.apply(check_urban_tract, axis = 1) # axis = 1 means apply to rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "davidson_tracts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are rural tracts, we know we need to expand our search area, we can do that by creating a new GeoPandas object where a `buffer` is added around the county:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geopandas buffers are calculated based on the crs of the gdf. Since we are using \"EPSG:4326\" we know the units are degrees. Using this conversion from the USGS (https://www.usgs.gov/faqs/how-much-distance-does-a-degree-minute-and-second-cover-your-maps?qt-news_science_products=0#qt-news_science_products): \"One degree of latitude equals approximately 364,000 feet (69 miles), one minute equals 6,068 feet (1.15 miles), and one-second equals 101 feet.\" We can approximate the number of degrees in a mile as: 1/69 = 0.014492753623188406"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "davidson_county_buffer_10 = gpd.GeoDataFrame(geometry = davidson_county['geometry'].buffer(0.14492753623188406),\n",
    "                                          crs = \"EPSG:4326\")\n",
    "ax = davidson_county_buffer_10.plot(figsize = (7, 7))\n",
    "davidson_county.boundary.plot(ax = ax, edgecolor = 'white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can add a grid to the expanded search area to break the search down into smaller pieces. We can start by finding the absolute x and y boundaries of the search area:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find total geographic bounds of search area\n",
    "\n",
    "xmin,ymin,xmax,ymax = davidson_county_buffer_10.total_bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on a little experimentation, a good spacing for the grid points is by dividing the total bounds for Davidson County itself by 10. So let's do that now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find total geographic bounds of Davidson County\n",
    "\n",
    "xmin_d,ymin_d,xmax_d,ymax_d = davidson_county.total_bounds\n",
    "\n",
    "# Divide the length and width by 10 to get the increment between each grid point\n",
    "\n",
    "x_increment = (xmax_d-xmin_d)/10\n",
    "y_increment = (ymax_d-ymin_d)/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can proceed with setting up the search grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine x coordinate values for grid points\n",
    "grid_x_boundaries = [xmin]\n",
    "new_bound = xmin\n",
    "for i in range(int((xmax-xmin)/x_increment)+1):\n",
    "    new_bound = new_bound + x_increment\n",
    "    grid_x_boundaries.append(new_bound)\n",
    "    \n",
    "# determine x coordinate values for grid points\n",
    "grid_y_boundaries = [ymin]\n",
    "new_bound = ymin\n",
    "for i in range(int((ymax-ymin)/y_increment)+1):\n",
    "    new_bound = new_bound + y_increment\n",
    "    grid_y_boundaries.append(new_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of all lats and lons across all grid points\n",
    "lons = []\n",
    "lats = []\n",
    "for left, right in zip(grid_x_boundaries[:-1], grid_x_boundaries[1:]):\n",
    "    for top, bottom in zip(grid_y_boundaries[:-1], grid_y_boundaries[1:]):\n",
    "        lats.append((top+bottom)/2)\n",
    "        lons.append((left+right)/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By converting the coordinate pairs to `point` objects, we can put them into a geodataframe and then we can easily perform a number of geographic calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take each pair of longitude and latitude, combine them, and convert to point object\n",
    "grid_points = gpd.points_from_xy(lons, lats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put into geodataframe\n",
    "grid_gdf = gpd.GeoDataFrame(geometry = grid_points, crs = \"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep points within the buffered Davidson county polygon\n",
    "keep_points = []\n",
    "for ind, p in grid_gdf['geometry'].iteritems():\n",
    "    if p.within(davidson_county_buffer_10.loc[0, 'geometry']) or p.within(davidson_county_buffer_10.loc[1, 'geometry']):\n",
    "        keep_points.append(ind)\n",
    "\n",
    "grid_points_sub = grid_gdf.loc[keep_points].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = davidson_county_buffer_10.plot(color='white', edgecolor='black')\n",
    "\n",
    "grid_points_sub.plot(ax=base, marker='o', color='red', markersize=5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that all the points are within the search area. The reason there is an additional circle in the search area is because Davidson County has a part that is disconnected from the main area.\n",
    "\n",
    "Now that we have all the coordinate points we want to search nearby, we can figure out what an appropriate radius would be. The radius is measured in meters. Measuring distance with lat and lng is a little different since you need to take into consideration the curviture of the earth. To do that we can use the `haversine distance` formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function adapted from https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.haversine_distances.html\n",
    "def dist_in_meters(point_1, point_2):\n",
    "    point_1 = [math.radians(l) for l in [point_1.y, point_1.x]]\n",
    "    point_2 = [math.radians(l) for l in [point_2.y, point_2.x]]\n",
    "    dist_array_m = haversine_distances([point_1, point_2])*6371000\n",
    "    return dist_array_m[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will select a radius that is the distance between two adjacent points. This will cause some amount of overlap, but it will also maximize the chances a relevant store will be returned, if it is not retured from another point for some reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_point_radius = dist_in_meters(grid_points_sub.loc[1, 'geometry'], grid_points_sub.loc[2, 'geometry'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the search area for each point on our map to make sure our entire search area is covered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_point_radius_mile = 3.0258050367212114828/69\n",
    "grid_points_sub_buffers = gpd.GeoDataFrame(geometry = grid_points_sub['geometry'].buffer(grid_point_radius_mile),\n",
    "                                          crs = \"EPSG:4326\")\n",
    "f, ax = plt.subplots(1, figsize=(15, 15))\n",
    "ax = davidson_tracts.boundary.plot(ax=ax, edgecolor = 'blue', color='blue', alpha = 0.15)\n",
    "ax = davidson_county.boundary.plot(ax=ax, color='blue', alpha = 0.15)\n",
    "ax = grid_points_sub_buffers.plot(ax=ax, color = '#ff7f00', alpha = 0.1)\n",
    "grid_points_sub.plot(ax=ax, marker='o', color='#4e2853', markersize=5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that Davidson County is entirely covered, as well 10 miles surrounding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now with grid points laid out across county we can figure out which types of stores to look for.\n",
    "\n",
    "Google Maps has a number of business types (https://developers.google.com/places/supported_types). Looking through them, all relevant store types are these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_types = ['bakery',\n",
    "             'convenience_store',\n",
    "             'department_store',\n",
    "             'drugstore',\n",
    "             'gas_station',\n",
    "             'grocery_or_supermarket',\n",
    "             'home_goods_store',\n",
    "             'supermarket',\n",
    "             'pharmacy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fully search for all stores across the entire county we would have to search each grid point for each store type. That will take a very long time. Additionally, it would require setting up an app on google to use for making the API requests. I've already run the code but we can walk through the steps for getting the data.\n",
    "\n",
    "The function for actually making the API calls is here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified from https://python.gotrained.com/google-places-api-extracting-location-data-reviews/\n",
    "\n",
    "def search_places_by_coordinate(location, radius, types, api_key, sleep_sec = 2):\n",
    "    '''\n",
    "    Send request to nearbysearch Google Maps endpoint\n",
    "    \n",
    "    location: The lat and lng to search nearby, \"lat, lng\"\n",
    "    radius: The distance, in meters, to search around the location\n",
    "    types: List of business types to search for\n",
    "    api_key: Credentials provided by Google to authenticate use of the API\n",
    "    sleep_sec: Number of seconds to wait between individual requests to throttle and avoid quotas\n",
    "    '''\n",
    "    # This is the endpoint where the request will be sent\n",
    "    endpoint_url = \"https://maps.googleapis.com/maps/api/place/nearbysearch/json\"\n",
    "    \n",
    "    places = [] # Where the responses will be saved\n",
    "    \n",
    "    # Formatting the request inputs\n",
    "    params = {\n",
    "        'location': location,\n",
    "        'radius': radius,\n",
    "        'types': types,\n",
    "        'key': api_key\n",
    "    }\n",
    "    \n",
    "    # Make the request to the endpoint with the associated parameters and save the output\n",
    "    res = requests.get(endpoint_url, params = params)\n",
    "    \n",
    "    # Read the contents of the response, which is a json, into a dictionary to make it easier to work with\n",
    "    results =  json.loads(res.content)\n",
    "    \n",
    "    # Add the results to the any previous results\n",
    "    places.extend(results['results'])\n",
    "    \n",
    "    # Wait before the next request\n",
    "    time.sleep(sleep_sec)\n",
    "    \n",
    "    # If there are still more items available, the response will contain a next_page_token to pick up at the same spot\n",
    "    # As long as there is a next_page_token, keep making requests\n",
    "    while \"next_page_token\" in results:\n",
    "        params['pagetoken'] = results['next_page_token'],\n",
    "        res = requests.get(endpoint_url, params = params)\n",
    "        results = json.loads(res.content)\n",
    "        places.extend(results['results'])\n",
    "        time.sleep(sleep_sec)\n",
    "    \n",
    "    # Once there are no more next_page_tokens, return the full list of stores\n",
    "    return places"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since many stores will be returned I created a separate list to add all the responses so they will persist even if there is an issue with a request or there is an interruption for some reason. This will allow me to pick up where it left off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating output list in separate cell in case need to run for loop multiple times because of time out errors\n",
    "responses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To systematically search the entire county for all store types I made a nested for loop that will search for each store type across all grid points and append the responses to the master list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This cell will not run since no `api_key` is provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This one can take a while, run with caution\n",
    "\n",
    "for ind_2, t in enumerate(all_types):\n",
    "    print(ind_2, t) # just to keep track of progress\n",
    "    # if ind_2 >= 1: # uncomment and tab below over if need to start later in all_types list\n",
    "    for ind, (lng, lat) in enumerate(list(zip(grid_points_sub['geometry'].x, grid_points_sub['geometry'].y))): # note that lat and lng are switched\n",
    "        # print(ind, lat, lng) # again, to keep track of progress\n",
    "        # if ind >= 0: # uncomment and tab below if need to start later in grid df\n",
    "        location = '{}, {}'.format(lat, lng)\n",
    "        responses.append(search_places_by_coordinate(location, grid_point_radius, t, api_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### After this ran I cleaned the data, converted to a gdf, and saved it off as a .shp file. Now we can import it again and continue using the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_gdf = gpd.read_file(\"data/google_api_stores_cleaned.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(15, 15))\n",
    "ax.set_facecolor('#ebecfe')\n",
    "ax = davidson_tracts.plot(ax=ax, column = 'above_20_pct', categorical = True, cmap = 'Set1', edgecolor = '#377eb8', alpha = 0.5)\n",
    "ax = davidson_county.boundary.plot(ax=ax, color='#377eb8')\n",
    "stores_gdf.plot(ax=ax, marker='o', color='#984ea3', markersize=5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we've added the stores to the map we can start to see areas with many stores and areas with few stores, and how those compare to tracts above and below 20% poverty\n",
    "\n",
    "However they may still be some cleaning we should do, as not all of the stores may actually offer fresh food. Looking at the first few rows of `stores_df`, we can see a **Twice Daily** and a **Panera Bread**, which aren't actually what we want. Let's try and filter down our stores to just ones that are classified as `supermarket`s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supermarkets = stores_gdf[stores_gdf['types'].apply(lambda x: 'supermarket' in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supermarkets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supermarkets.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that only keeping rows that have a `type` of `'supermarket'`, greatly reduces the number of stores. Also, in general this seems to be filtering how we want it to filter (we can see many **Publix** stores), but we can also see things that maybe shouldn't be there (like **Dollar General**). \n",
    "\n",
    "The influence of dollar stores on food deserts is an area if interest (https://www.cbsnews.com/news/dollar-stores-and-food-deserts-the-latest-struggle-between-main-street-and-corporate-america/). Though some sources indicate that they do not sell fresh produce, the Dollar General website indicates that produce is available in their stores (https://www.dollargeneral.com/catalogsearch/result/?q=produce) but there is no category for fresh foods (https://www.dollargeneral.com/food.html).\n",
    "\n",
    "For this analysis we will exclude dollar stores from _stores selling fresh food_. That means we will need to remove them from our list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_dollar_supermarkets = supermarkets[~supermarkets['name'].str.contains('Dollar')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For completeness, let's double check the non-supermarkets to make sure we're not leaving anything we want behind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_supermarkets = stores_gdf[~stores_gdf['types'].apply(lambda x: 'supermarket' in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_supermarkets['name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A little investigation would show that a slight concern is **Kroger** is in the `non-supermarkets` list. Let's double check to see if **Kroger** is included in the `supermarkets` df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_dollar_supermarkets[non_dollar_supermarkets['name'].str.contains('Kroger')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one **Kroger**, but that means we are likely missing many others. Let's get the **Kroger** stores and add them back to the `supermarkets` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kroger = stores_gdf[stores_gdf['name'].str.contains('Kroger')]\n",
    "\n",
    "non_dollar_supermarkets = non_dollar_supermarkets.append(kroger)\n",
    "\n",
    "non_dollar_supermarkets.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that cleaning done, let's plot the supermarkets on the map and see where we stand now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(15, 15))\n",
    "ax.set_facecolor('#ebecfe')\n",
    "ax = davidson_tracts.plot(ax=ax, column = 'above_20_pct', categorical = True, cmap = 'Set1', edgecolor = '#377eb8', alpha = 0.5)\n",
    "ax = davidson_county.boundary.plot(ax=ax, color='#377eb8')\n",
    "non_dollar_supermarkets.plot(ax=ax, marker='o', color='#984ea3', markersize=5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are far fewer now, but the spread seems similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that we have a list of stores that sell fresh food, we can find the low income census tracts where at least a third is more than a mile (or 10 miles for rural tracts) away from them.\n",
    "\n",
    "To address that we will add buffers around the stores that correspond to a 1 mile radius.\n",
    "\n",
    "The buffers will be separate objects, so we will create a new gdf for them. Recall that we can approximate the number of degrees in a mile as: 1/69 = 0.014492753623188406"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urban_store_buffers = gpd.GeoDataFrame(geometry = non_dollar_supermarkets[non_dollar_supermarkets['rural_only']==0]['geometry'].buffer(0.014492753623188406),\n",
    "                                          crs = \"EPSG:4326\")\n",
    "\n",
    "rural_store_buffers = gpd.GeoDataFrame(geometry = non_dollar_supermarkets['geometry'].buffer(0.14492753623188406),\n",
    "                                          crs = \"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will not add buffers for a 10 mile radius since those will obscure much of the map. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(15, 15))\n",
    "ax.set_facecolor('#ebecfe')\n",
    "ax = davidson_tracts.plot(ax=ax, column = 'above_20_pct', categorical = True, cmap = 'Set1', edgecolor = '#377eb8', alpha = 0.5)\n",
    "ax = davidson_county.boundary.plot(ax=ax, color='#377eb8')\n",
    "ax = non_dollar_supermarkets.plot(ax=ax, marker='o', color='#984ea3', markersize=10)\n",
    "urban_store_buffers.plot(ax=ax, color = '#4daf4a', alpha = 0.1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we can start to see with more clarity where the food deserts actually are. To really nail it down, let's calculate the exact proportion of each census tract that is too far away from a fresh food source.\n",
    "\n",
    "There are many ways we can accomplish this, but an easy way is to combine all the store buffers into a single shape, then check the proportion of each tract that overlaps with that shape. Since we are differentiating rural and urban tracts, let's also make different store buffers to check against.\n",
    "\n",
    "To combine the buffer shapes, we can use the `unary_union()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urban_store_buffers = unary_union(urban_store_buffers['geometry'])\n",
    "rural_store_buffers = unary_union(rural_store_buffers['geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_low_food_access(row):\n",
    "    if row['is_rural'] == 1:\n",
    "        return (row['geometry'] - rural_store_buffers).area/row['geometry'].area\n",
    "    else:\n",
    "        return (row['geometry'] - urban_store_buffers).area/row['geometry'].area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check tract on row 3 of census tract df\n",
    "check_low_food_access(davidson_tracts.loc[2, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entire tract on row 3 of the census tract df is within a mile of a fresh food source, indicating it does not have low food access.\n",
    "\n",
    "_**Now we can expand this to find all the possible food deserts in Davidson County.**_ Recall our criteria for possible food deserts:\n",
    "1. Poverty level in a census tract is >= 20% (low income)\n",
    "2. At least 33% of the census tract is >1 mile from a fresh food source in urban areas or >10 miles for rural areas (low access)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "davidson_tracts['ratio_low_food_access'] = davidson_tracts.apply(check_low_food_access, axis = 1)\n",
    "\n",
    "davidson_tracts['possible_food_desert'] = ((davidson_tracts['ratio_low_food_access'] > 0.33) & (davidson_tracts['above_20_pct'] == 1)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "davidson_tracts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(15, 15))\n",
    "ax.set_facecolor('#ebecfe')\n",
    "ax = davidson_tracts.plot(ax=ax, column = 'possible_food_desert', categorical = True, cmap = 'Set1', edgecolor = '#377eb8', alpha = 0.5)\n",
    "ax = davidson_county.boundary.plot(ax=ax, color='#377eb8')\n",
    "ax = non_dollar_supermarkets.plot(ax=ax, marker='o', color='#984ea3', markersize=10)\n",
    "ax = davidson_service_districts[davidson_service_districts['name']=='Urban Services District'].plot(ax=ax, alpha = 0.2, edgecolor = 'black', linewidth = 3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# According to our analysis, the census tracts in gray are possible food deserts. How would you interpret the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nash_map = folium.Map(location =  [36.1612, -86.7775], zoom_start = 11)\n",
    "folium.GeoJson(unary_union(davidson_tracts[davidson_tracts['possible_food_desert']==1]['geometry'])).add_to(nash_map)\n",
    "nash_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
